\documentclass{elsarticle}

\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}

\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\lstset{
  basicstyle=\footnotesize\ttfamily,
  columns=fullflexible,
  showstringspaces=false,
  commentstyle=\color{gray}\upshape,
  frame=single
}

\lstdefinelanguage{XML}
{
  morestring=[b]",
  morestring=[s]{>}{<},
  morecomment=[s]{<?}{?>},
  morecomment=[s]{<!--}{-->},
  stringstyle=\color{black},
  identifierstyle=\color{darkblue},
  keywordstyle=\color{cyan},
  morekeywords={}
}

\begin{document}

\title{The OpenMC Monte Carlo Particle Transport Code\tnoteref{t1}}
\tnotetext[t1]{This research was performed under appointment to the Rickover
  Fellowship Program in Nuclear Engineering sponsored by Naval Reactor Division
  of the U.S. Department of Energy.}
\author[mit]{P.K. Romano\corref{cor1}}
\ead{paul.k.romano@gmail.com}
\cortext[cor1]{Corresponding author}

\author[mit]{B. Forget}
\ead{bforget@mit.edu}

\author[mit]{K. Smith}
\ead{kord@mit.edu}

\address[mit]{Massachusetts Institute of Technology, Department of Nuclear
  Science and Engineering, 77 Massachusetts Avenue, Building 24-213, Cambridge,
  MA 02141}

\begin{abstract}
A new Monte Carlo code called OpenMC is currently under development at the
Massachusetts Institute of Technology as a tool for simulation on
high-performance computing platforms. Given that many legacy codes do not scale
well on existing and future parallel computer architectures, OpenMC has been
developed from scratch with a focus on high performance scalable algorithms as
well as modern software design patterns. The present work describes the methods
used in the OpenMC code and demonstrates the performance and accuracy of the
code on a variety of problems.
\end{abstract}

\maketitle

\section{Introduction}

The introduction of exascale computing in the next decade will introduce a
variety of challenges both for hardware and software developers. As such,
research and development efforts are underway aimed at enabling high-fidelity,
large-scale simulations that will scale on current and future computer
achitectures. To support these studies, a new Monte Carlo code has been under
development since early 2011 at the Massachusetts Institute of Technology. The
goal in developing a new Monte Carlo code rather than using a previously
developed code is to have a code that is easily extensible for research purposes
in addition to being high performance, freely available, and written in a modern
programming language.

\section{Methods}

\subsection{Physics}

The initial work on OpenMC has focused on criticality calculations as applied to
the simluation of nuclear reactors. The solution of the eigenvalue problem
proceeds by the method of successive generations \cite{lieberoth} wherein a
constant number of neutron histories are tracked from birth to death. The data
governing the interaction of neutrons with various nuclei are represented using
the ACE format \cite{ace-format} which is used by MCNP \cite{mcnp} and Serpent
\cite{serpent}. ACE-format data can be generated with the NJOY nuclear data
processing system which converts raw ENDF/B data into linearly-interpolable data
as required by most Monte Carlo codes. The use of a standard cross section
format allows for a direct comparison of OpenMC with other codes since the same
cross section libraries can be used.

The ACE-format contains continuous-energy cross sections for the following types
of reactions: elastic scattering, fission (or first-chance fission,
second-chance fission, etc.), inelastic scattering, (n,xn), (n,$\gamma$), and
various other absorption reactions. For those reactions with one or more
neutrons in the exit channel, secondary angle and energy distributions may be
present. In addition, fissionable nuclides have total, prompt, and/or delayed
$\nu$ as a function of energy and neutron precursor distributions. Many nuclides
also have probability tables to be used for accurate treatment of self-shielding
in the unresolved resonance range. For bound scatterers, separate tables with
$S(\alpha,\beta)$ scattering law data can be used.

One important aspect of a Monte Carlo code is the manner in which cross sections
are determined. In general, cross sections are represented as tabulated
functions of energy that are linearly interpolated between sucessive
values. However, the energy values at which cross sections are tabulated are
different from one nuclide to another. Thus, in order to determine the total
cross section of a material, it may be necessary to do a binary search on the
energy grid of each nuclide within the material. In the Serpent Monte Carlo
code, a unionized energy grid is constructed and used for all nuclides as
described in a recent work by Leppanen. The downside of a unionzied energy grid
is that the memory requirement may be prohibitively high for problems with many
nuclides. 

OpenMC uses an indexing technique to give the same algorithmic benefit of a
unionized grid while requiring much less memory. First, an array of energy
values is constructud that is the union of all points on each nuclide energy
grid. Then, an array of pointers is stored for each nuclide that gives the
corresponding index on the nuclide energy grid for each value on the union
energy grid. This technique does not require that the array of cross-sections
for each nuclide be modified in any way; instead, the extra array of pointers
for each nuclide provides a quick means of determining what indices to
interpolate between when calculating a cross section given the index on the
union energy grid.

For neutrons at higher energies, it can be safely assumed that the motion of the
target nucleus is negligible relative to the velocity of the neutron
itself. However, in the thermal and intermediate energy ranges, the target
velocity will alter both the cross sections and the secondary energy and angle
distributions of scattered neutrons. To account for the effect on cross
sections, Doppler broadening is typically performed in the cross section
generation stage. For the angle and energy distributions, OpenMC uses a free gas
approximation \cite{freegas} wherein the velocity of the target nuclei have a
Maxwellian distribution. For thermal neutrons scattering from bound molecules
such as hydrogen or deuterium in water, graphite, beryllium, etc., the free gas
approximation will not accurately capture the scattering kinematics and
$S(\alpha,\beta)$ scattering law data must be used.

In the unresolved resonance energy range, it is not adequate to use smooth cross
sections since the experimental resolution is not fine enough to resolve all
resonances. To properly account for self-shielding in this energy range, OpenMC
uses the probability table method \cite{probtables}. For most thermal and fast
reactors, the use of probability tables will not significantly affect problem
results. However, for some problems with an appreciable flux spectrum in the
unresolved resonance range, not using probability tables will lead to incorrect
results \cite{probtables-testing}.

\subsection{Geometry}

In order to model arbitrarily complex geometric objects, OpenMC uses a
constructive solid geometry representation. In such a representation, any closed
volume can be represented as the union, intersection, and/or difference of
multiple half-spaces. Each half-space is in turn defined as the positive or
negative side of a plane or quadratic surface. This allows curved surfaces such
as spheres and cylinders to be modeled exactly with no error due to mesh
discretization. Almost all geometries of interest in particle transport can be
modeled with first and second-order surfaces with the exception of some fusion
geometries where a fourth-order torus is used.

As is typical in most Monte Carlo codes, OpenMC provides constructs that allow
the user to model a two or three-dimensional structured mesh consisting of
quadrilaterals or hexagons. These constructs are useful for modeling the core
and assembly layout in a typical light-water reactor or the hexagonal layout in
a VVER. As in MCNP and Serpent, these repeated structured are handled through
the use of universes. Transmitting, vacuum, or reflective boundary conditions
can be applied to any surface giving the user full flexibility in the treatment
of boundaries.

As OpenMC continues to mature, it is likely that more geometric constructs will
become available that give the user more flexibility and aid model generation.

\subsection{Tallies}

The tally capabilities in OpenMC are roughly based off the tally system
implemented in MC21 \cite{MC21}. The user can specify one or more filters which
identify which regions of phase space should score to a given tally as well as
the scoring function. For example, if the desired tally was the $(n,\gamma)$
reaction rate in a fuel pin, the filter would specify the cell which contains
the fuel pin and the scoring function would be the radiative capture reaction
rate. The following scoring functions are currently available: flux, total
reaction rate, scattering reaction rate, neutron production from scattering
\cite{herman}, higher scattering moments, $(n,xn)$ reaction rates, absorption
reaction rate, fission reaction rate, neutron production rate from fission, and
surface currents. The following variables can be used as filters: universe,
material, cell, birth cell, surface, mesh, pre-collision energy, and
post-collision energy.

With filters for pre- and post-collision energy and scoring functions for
scattering and fission production, it is possible to use OpenMC to generate
cross-sections needed for determinstics solvers such as coarse-mesh finite
diffusion.

As has been demonstrated \cite{mcnp-efficiency}, some Monte Carlo codes suffer
severe performance penalties when tallying a large number of quantites. Care
must be taken to ensure that a tally system scales well with the total number of
tally bins. In OpenMC, a mapping technique is used that allows for a fast
determination of what tally/bin combinations need to be scored to a given
particle's phase space coordinates. For each discrete filter variable, a list of
tally and bin combinations is created at the start of the simulation which would
be scored to for every possible value of the filter variable. If a particle is
in cell $n$, the mapping would tell us what tally/bin combinations specify cell
$n$ for the cell filter variable. In this manner, it is not necessary to check
the phase space variables against each tally. Note that this technique only
applies to discrete filter variables and cannot be applied to energy bins. For
energy filters, it is necessary to perform a binary search on the specified
grid.

\subsection{File Formats}

Given that many Monte Carlo particle transport codes have been in production use
for decades, it is perhaps not surprising that their user input formats are
reminiscent of the days when decks of punch cards had to be used to perform a
simulation. Each code generally has its own arbitrary format for specifying
input and, unfortunately, these formats are generally not ``user-friendly''. To
a new user of some Monte Carlo codes, an input file may appear as merely a
conglomeration of numbers in an ASCII file with no apparent meaning. Thus, when
OpenMC was designed, it was decided that the user input should be standardized
to a format which would be easy-to-use as well as convenient for code developers
to modify and extend.

Rather than use an arbitrary text format, OpenMC uses Extensible Markup Language
(XML) [REF] for all user input files. The XML format makes it easy for a user to
visually inspect an input file and determine its contents as well as for the
code developer who must write a routine that reads the input. All the input for
a simulation is specified in multiple files that are logically grouped instead
of one long input file. In the present version of OpenMC, separate XML input
files are created for the geometry, the materials, miscellaneous settings, and
tallies. Further extensions to the code may add additional input files such as
input parameters for OpenMC accelerated by coarse-mesh finite difference
methods.

To demonstrate the salient features of the user input format, let us look at an
example of a set of input files from a real model, in this case the
U233-MET-FAST-002 benchmark problem from the International Handbook of Evaluated
Criticality Safety Benchmark Experiments \cite{icsbep}. This benchmark has a
single spherical region with enriched U-233 metal surrounded by a spherical
shell of U-235. Figure \ref{fig:geometry-xml} shows the geometry.xml file which
describes the constructive solid geometry model. A few points should be made
regarding this file. Firstly, the order in which the \textless cell\textgreater
and \textless surface \textgreater elements appear is not of any
consequence. Secondly, the attributes on the cell and surface elements could
have appeared as sub-elements defining the same parameters. This gives extra
flexibility to the user in how they choose to define their input. Figure
\ref{fig:materials-xml} shows the materials.xml file describing the materials
that fill the two regions in the solid geometry model. The units for the density
of the material are written explicitly and can be given in other formats such as
atoms per barn-cm. On the \textless nuclide \textgreater elements, ``ao'' stands
for atom fraction. Weight fractions can alternatively be specified with the
``wo'' attribute. Figure \ref{fig:settings-xml} shows the settings.xml file that
describes all simulation parameters and other options that the code should or
should not use. Lastly, Figure \ref{fig:tallies-xml} shows the tallies.xml that
specifies what quantities the user wants to determine from the simulation. In
this case, the code will give the nu-fission reaction rate, $\nu\Sigma_f\phi$,
in the U-233 sphere and the U-235 shell, each over two energy groups.

\begin{figure}
  \begin{lstlisting}[language=xml]
<?xml version="1.0"?>
<geometry>

  <cell id="1" material="1" surfaces="-1"/>
  <cell id="2" material="2" surfaces="1 -2"/>

  <surface id="1" type="sphere" coeffs="0. 0. 0. 4.5999"/>
  <surface id="2" type="sphere" coeffs="0. 0. 0. 6.5887" boundary="vacuum"/>

</geometry>
  \end{lstlisting}
  \caption{Geometry XML file for benchmark model U233-MET-FAST-002.}
  \label{fig:geometry-xml}
\end{figure}

\begin{figure}
  \begin{lstlisting}[language=xml]
<?xml version="1.0"?>
<materials>

  <default_xs>70c</default_xs>

  <material id="1">
    <density value="18.644" units="g/cm3" />
    <nuclide name="U-233" ao="4.7312e-2" />
    <nuclide name="U-234" ao="5.2770e-4" />
    <nuclide name="U-238" ao="3.3015e-4" />
  </material>

  <material id="2">
    <density value="18.80" units="g/cm3" />
    <nuclide name="U-235" ao="4.4892e-2" />
    <nuclide name="U-238" ao="3.2340e-3" />
  </material>

</materials>
  \end{lstlisting}
  \caption{Material XML file for benchmark model U233-MET-FAST-002.}
  \label{fig:materials-xml}
\end{figure}

\begin{figure}
  \begin{lstlisting}[language=XML]
<?xml version="1.0"?>
<settings>
 
  <criticality>
    <cycles>3000</cycles>
    <inactive>20</inactive>
    <particles>10000</particles>
  </criticality>

  <source>
    <type>box</type>
    <coeffs>-1 -1 -1  1  1  1</coeffs>
  </source>

</settings>
  \end{lstlisting}
  \caption{Settings XML file for benchmark model U233-MET-FAST-002.}
  \label{fig:settings-xml}
\end{figure}

\begin{figure}
  \begin{lstlisting}[language=XML]
<?xml version="1.0"?>
<tallies>

  <tally id="1">
    <filters>
      <cell>1 2</cell>
      <energy>0.0 0.653e-6 20.0</energy>
    </filters>
    <macros>nu-fission</macros>
  </tally>

</tallies>
  \end{lstlisting}
  \caption{Tallies XML file for benchmark model U233-MET-FAST-002.}
  \label{fig:tallies-xml}
\end{figure}

\subsection{Parallelism}

One weakness in many Monte Carlo codes is the ability to run a simulation with
more than a few dozen processors and attain good parallel scalability. In
criticality calculations, this sub-optimal performance is largely related to the
implementation of the fission bank, an array in memory where fission sites are
stored during one generation of neutrons and sampled to select sites for a
subsequent generation of neutrons. A typical parallel implementation of the
fission bank relies on all processes sending their fission sites to one master
process who then sorts and broadcasts the source sites for the next generation.

In OpenMC, a new algorithm has been developed that overcomes the poor
scalability of typical parallel fission bank algorithms
\cite{fissionbank}. Since the source sites for each generation are sampled from
the fission sites banked from the previous generation, it is a common occurrence
for a fission site to be banked on one process and sent back to the master only
to get sent back to the same process as a source site. As a result, much of the
communication inherent in the typical fission bank algorithm is entirely
unnecessary. By keeping the fission sites local, having each process sample
fission sites, and sending sites between processes only as needed, one can cut
down on most of the communication. The algorithm in OpenMC works as follows:

\begin{enumerate}
\item An exclusive scan is performed on the number of sites banked, and the
  total number of fission bank sites is broadcasted to all processes. By
  picturing the fission bank as one large array distributed across multiple
  processes, one can see that this step enables each process to determine the
  starting index of fission bank sites in this array. Let us call the starting
  and ending indices on the $i$-th process $a_i$ and $b_i$, respectively;
\item Each process samples sites at random from the fission bank using the same
  starting seed. A separate array on each process is created that consists of
  sites that were sampled local to that process, {\em i.e.} if the index of the
  sampled site is between $a_i$ and $b_i$, it is set aside;
\item If $a_i$ is less than $iN/p$ where $N$ is the total number of particles
  per generation and $p$ is the number of processors, then send $iN/p - a_i$
  sites to the left adjacent process. Similarly, if $a_i$ is greater than
  $iN/p$, then receive $a_i - iN/p$ from the left adjacent process. This idea is
  applied to the fission bank sites at the end of each process' array as
  well. If $b_i$ is less than $(i+1)N/p$, then receive $(i+1)N/p - b_i$ sites
  from the right adjacent process. If $b_i$ is greater than $(i+1)N/p$, then
  send $b_i - (i+1)N/p$ sites to the right adjacent process. Thus, each process
  sends/receives only two messages under normal circumstances.
\end{enumerate}

It was shown \cite{fissionbank} that the maximum expected communication cost
from this algorithm is independent of the number of processes and instead is
proportional to the square root of the number of particles per generation. In
other words, this algorithm is $O({\sqrt{N}})$ where a traditional algorithm
would be $O({N})$.

\subsection{Code Development}

One of the substantial benefits of writing a code from scatch is that it is
natural to take advantage of modern software practices. This applies to every
aspect of code development including the choice of programming language,
compilers used, version control system, and documentation. It is instructive to briefly
discuss the software development methodology and key decision made that affect
future development.

OpenMC is written in standard Fortran 2003. While C and C++ were considered as
other possible languages for development, ultimately Fortran 2003 was chosen due
to MIT's research focus on parallel algorithms coupled with the availability of
co-array features in the Fortran 2008 standard. For input processing, OpenMC
relies on a modified version of the xml-fortran \cite{xml-fortran}
parser. Almost all important data are encapsulated in derived types. While
object-oriented features are available in Fortran 2003, they have not yet been
employed in OpenMC due to limited compiler support. OpenMC has been successfully
compiled with the gfortran, Intel, PGI, Cray, and IBM compilers with various
platforms including several Linux distributions and Mac OS X.

Rather than use cvs or svn for version control as is common for older software,
we chose to use the git distributed revision control system. The advantages of a
modern version control system like git or mercurial over cvs and svn are
numerous and will not be listed here. In addition to git, the web-based hosting
service github is used to provide a central host, issue tracking, a wiki, and
documentation hosting. The combination of git and github greatly enables
developers to maintain high productivity in collaborating with one another,
testing out new ideas, and documentating their work.

\section{Results}

\subsection{Tally Performance}

\subsection{Parallel Scaling}

\subsection{Benchmarks}

In order to verify that the geometry and physics models implemented in OpenMC
are working correctly, a number of benchmark models have been constructed for
OpenMC, and key results were compared with those from MCNP5. Since OpenMC is
capable of using the same ACE format cross-sections as MCNP5, any differences in
results between the two codes will be limited to those arising from the geometry
and physics algorithms. The benchmark problems here were specifically chosen to
test extreme cases that would lead to large differences in results if the
underlying algorithms were not implemented correctly.

\subsubsection{Thermal Scattering}

For problems that have a thermal spectrum such as a typical commercial
light-water reactor, it is essential to correctly treat the scattering of
neutrons from bound scatterers such as hydrogen in water. One model that
highlights differences in the bound-scattering treatment is a very simple
pin-cell model proposed by Cullen et al. \cite{pincell}. This problem consists
of an infinite lattice of fuel pins with a 2 inch pitch and varying fuel pin
radius. The fuel is solely U-235 and U-238 and there is no gap or cladding on
the fuel. The water is not borated, i.e. consists only of Hydrogen and
Oxygen. By having a very simple model, the problem achieves two goals:
\begin{enumerate}
  \item There is no ``correct'' answer to the problem, and thus those
    participating in the benchmark don't have a preconceived notion of whether
    their own results are correct.
  \item Since the materials are very simple, any differences in answers can be
    almost solely attributed to the bound-scattering treatment.
\end{enumerate}

The paper on this benchmark suggested six cases to run corresponding to each
combination of three different fuel pin radii and two different scattering
treatments. The fuel pin radii specified were 1/2, 1/4, and 1/8-th of an inch,
and each of those models was to be run first with and without the
$S(\alpha,\beta)$ scattering treatment. The report showed that between the 10
different Monte Carlo codes used, there were differences in k-effective of up to
2\% even for such a simple model. Of course, there are numerous reasons for the
vast spread of results between codes including different cross-section libraries
(ENDF/B-VI, ENDF/B-V, JEFF), cross-section treatments (continuous-energy
vs. multigroup), user input definitions, and physics algorithms.

For the purposes of validating the $S(\alpha,\beta)$ treatment in OpenMC, we
compare the results of OpenMC on this simple ``benchmark'' to those from
MCNP5-1.51 using the same ENDF/B-VII.0 cross-section libraries. With the same
cross-section libraries and similar physics treatments, it would be expected
that the results between OpenMC and MCNP5 should be very close. Each case was
run with 50 inactive cycles and 1,000 active cycles, each with 10,000
particles. Table \ref{tab:pincell} shows k-effective and its uncertainty for the
six cases described above.

\begin{table}
  \caption{Effective Multiplication Factor for INDC(USA)-107 pin-cell problem.}
  \label{tab:pincell}
  \begin{center}
  \begin{tabular}{ l c c }
    \hline
    Case & MCNP5-1.51 & OpenMC \\
    \hline
    1/2\verb+"+ pin, no $S(\alpha,\beta)$ & $1.01669 \pm 0.00012$ & $1.01652 \pm 0.00006$ \\
    1/2\verb+"+ pin, $S(\alpha,\beta)$    & $0.96811 \pm 0.00013$ & $0.96809 \pm 0.00006$ \\
    1/4\verb+"+ pin, no $S(\alpha,\beta)$ & $1.01320 \pm 0.00016$ & $1.01325 \pm 0.00006$ \\
    1/4\verb+"+ pin, $S(\alpha,\beta)$    & $0.92197 \pm 0.00017$ & $0.92213 \pm 0.00006$ \\
    1/8\verb+"+ pin, no $S(\alpha,\beta)$ & $1.01320 \pm 0.00021$ & $1.01316 \pm 0.00006$ \\
    1/8\verb+"+ pin, $S(\alpha,\beta)$    & $0.90950 \pm 0.00021$ & $0.90921 \pm 0.00005$ \\
    \hline
  \end{tabular}
  \end{center}
\end{table}

\subsubsection{Unresolved Resonance Treatment}

Besides thermal scattering, the other energy range that requires special
treatment is the unresolved resonance range. For many nuclides, resonances in
the 1 to 100 keV energy range are so narrow and closely spaced that is not
possible to experimentally resolve the details of all resonances. In the absence
of any special techniques, one would have to use the dilute-average
cross-section in the unresolved range. This may be an acceptable approximation
for problems that are not sensitive to the unresolved resonance range (notably
LWRs and other thermal reactors), but for other problems it can result in
serious errors in reported answers.

Several benchmark problems are particularly sensitive to the unresovled
resonance treatment. We have chosen to compare results on a model of the Big Ten
critical assembly (IEU-MET-FAST-007 from the International Handbook of Evaluated
Criticality Safety Benchmark Experiments \cite{icsbep}) as a means of validating
the implementation of the probability table method in OpenMC. This assembly is a
large, mixed Uranium metal cylindrical core of 10\% enrichment surrounded by a
U-238 reflector. The version of the benchmark from the MCNP expanded criticality
validation suite \cite{mcnp-validation} is used. This version has been submitted
for inclusion in the Handbook but has not yet been approved.

The Big Ten benchmark was run using MCNP5-1.51 and OpenMC using the same
ENDF/B-VII.0 cross section libraries. In each case, 50 inactive cycles and 1,000
active cycles were used, each consisting of 10,000 particles. Table
\ref{tab:bigten} shows k-effective and its uncertainty for all runs. The results
clearly show that the unresolved resonance probability table treatment in OpenMC
has been implemented correctly, with results from MCNP agreeing within a few pcm
in reactivity.

\begin{table}
  \caption{Effective Multiplication Factor for Big Ten benchmark from MCNP
    expanded criticality validation suite.}
  \label{tab:bigten}
  \begin{center}
  \begin{tabular}{ l c c }
    \hline
    Case & MCNP5-1.51 & OpenMC \\
    \hline
    Probability tables off & $1.00096 \pm 0.00017$ & $1.00100 \pm 0.00006$ \\
    Probability tables on  & $1.00505 \pm 0.00022$ & $1.00488 \pm 0.00006$ \\
    \hline
  \end{tabular}
  \end{center}
\end{table}

\subsubsection{Full-Core Problems}

While the previous two benchmark problems are ideal for identifying differences
in the physics treatments, both have relatively simply geometries and a limited
number of nuclides. Thus, it is desirable to also compare results on a benchmark
with complicated geometry and materials. One such benchmark problem is the Monte
Carlo Performance Benchmark originally proposed by Hoogenboom and Martin
\cite{hoogenboom}. The specific aim of this benchmark is to monitor the increase
in performance of Monte Carlo calculations of full-core reactor problems. The
model consists of a typical PWR core layout with 241 fuel assemblies, each with
a 17 by 17 lattice of fuel pins including 21 control rod guide tubes. The fuel
is composed of 34 different nuclides: a mix of actinides, minor actinides, and
key fission products.

A model of the Monte Carlo Performance Benchmark was built for both MCNP5 and
OpenMC based on Revision 1.2 of the benchmark specification. To get an estimate
of the effective multiplication factor, each model was run with 10,000 particles
per cycle for 150 inactive and 1000 active cycles using the same ENDF/B-VII.0
libraries as before. Table \ref{tab:hoogenboom} shows the reported
multiplication factors from the two codes. Once again, there is remarkable
agreement between MCNP and OpenMC since the since cross-section libraries were
used.

\begin{table}
  \caption{Effective Multiplication Factor for the Monte Carlo Performance
    Benchmark Test.}
  \label{tab:hoogenboom}
  \begin{center}
  \begin{tabular}{ l c }
    \hline
    Code & k-effective \\
    \hline
    MCNP5-1.51 & $1.00026 \pm 0.00021$ \\
    OpenMC     & $1.00011 \pm 0.00006$ \\
    \hline
  \end{tabular}
  \end{center}
\end{table}

\section{Conclusions}

\bibliography{main}
\bibliographystyle{elsarticle-num}

\end{document}
